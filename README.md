# Feature-engineering
Feature Selection is one of the core concepts in machine learning which hugely impacts the performance of your model. The data features that you use to train your machine learning models have a huge influence on the performance you can achieve. Irrelevant or partially relevant features can negatively impact model performance. Feature selection and Data cleaning should be the first and most important step of your model designing.
Feature selection helps in the following ways
-Shorter training times
- Easy to interpret 
- Reduces overfitting
- improves accuracy


In this section I cover the three methods of feature engineering
- Filter methods
   - correlations, mutual information gain and various statistical test
- wrapper methods
- embedded methods
    lasso and ridge regression 
